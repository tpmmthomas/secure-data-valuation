{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malicious, multi-point scenario\n",
    "\n",
    "In this scenario, we assume Bob has multiple data points to contribute to Alice's ML model. Now Alice is trying to value the dataset as a whole, judging on the diversity, uncertainty of the datasets as well as the current model's performance on the dataset. Moreover, the parties are assumed to be malicious, which means they might deviate from the protocol to maximize their own utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup\n",
    "\n",
    "We set up Alice's model and Bob's data point as in the other examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#First, we define Alice's model M. We assume a simple CNN model.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#Don't use GPU for now\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "class LeNet(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Adaptation of LeNet that uses ReLU activations\n",
    "    \"\"\"\n",
    "\n",
    "    # network architecture:\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "model = LeNet()\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "torch.save(model.state_dict(), 'data/model.pth')\n",
    "torch.save(model, 'data/alice_model.pth')\n",
    "\n",
    "#Next, we define the data loader for CIFAR-10 dataset.\n",
    "import torchvision\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=False,transform=transform,download=True)\n",
    "\n",
    "\n",
    "# Randomly select 100 images as Bob's dataset\n",
    "indices = random.sample(range(len(trainset)), 100)\n",
    "selected_images = np.array([trainset[i][0].numpy() for i in indices])\n",
    "selected_labels = np.array([trainset[i][1]  for i in indices])\n",
    "\n",
    "# Save images and labels separately\n",
    "# torch.save(selected_images, 'data/selected_images.pth')\n",
    "# torch.save(selected_labels, 'data/selected_labels.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Clustering\n",
    "\n",
    "Before submitting points to Alice for evaluation, Bob needs to select a subset of representative data points. To do this, we recommend using K-means clustering to select a diverse set of points where K is defined by the number of data points Alice wishs to check. Bob can select a data point closest to the centroid of each cluster. It is ultimately up to Bob to decide which points to submit, even if they are not ideal so we do not need to securely compute this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers shape: (10, 3072)\n"
     ]
    }
   ],
   "source": [
    "#First, we run the Kmeans clustering algorithm locally on Bob's device\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set the number of clusters\n",
    "K = 10\n",
    "\n",
    "# Reshape the images to be a 2D array (each image is flattened)\n",
    "flattened_images = selected_images.reshape(selected_images.shape[0], -1)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(flattened_images)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "print(\"Cluster centers shape:\", cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further make an enhancement to pure K-means selection by trying to select the most uncertain points in each cluster. As determining the uncertainty requires model inference, we define a computing budget B which is the number of points Bob and Alice can afford to evaluate. \n",
    "\n",
    "In the malicious case however, computing model inference via a secure multi-party computation protocol is not very feasible, as such computation is extremely expensive. Therefore, we will allow Alice to see the data point (without labels) and compute the model inference herself. A ZKP will be required from Alice to prove the correctness of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0016], grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Set up\n",
    "\n",
    "#First, a slightly modified version of the model \n",
    "#that returns the difference between the top 2 probs of the output.\n",
    "class LeNetZKP(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Adaptation of LeNet that uses ReLU activations\n",
    "    \"\"\"\n",
    "\n",
    "    # network architecture:\n",
    "    def __init__(self):\n",
    "        super(LeNetZKP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        top2_values, _ = torch.topk(x, 2)\n",
    "        diff = top2_values[:, 0] - top2_values[:, 1]\n",
    "        return -diff\n",
    "\n",
    "modelZK = LeNetZKP()\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "y = modelZK(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directory if not exists\n",
    "os.makedirs('dataZKP', exist_ok=True)\n",
    "#Specifying some path parameters\n",
    "model_path = os.path.join('dataZKP','network.onnx')\n",
    "compiled_model_path = os.path.join('dataZKP','network.compiled')\n",
    "pk_path = os.path.join('dataZKP','test.pk')\n",
    "vk_path = os.path.join('dataZKP','test.vk')\n",
    "settings_path = os.path.join('dataZKP','settings.json')\n",
    "\n",
    "witness_path = os.path.join('dataZKP','witness.json')\n",
    "data_path = os.path.join('dataZKP','input.json')\n",
    "output_path = os.path.join('dataZKP','output.json')\n",
    "label_path = os.path.join('dataZKP','label.json')\n",
    "proof_path = os.path.join('dataZKP','test.pf')\n",
    "cal_path = os.path.join('dataZKP',\"calibration.json\")\n",
    "\n",
    "#Model export \n",
    "torch.onnx.export(modelZK,               # model being run\n",
    "    x,                   # model input (or a tuple for multiple inputs)\n",
    "    model_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=10,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = ['input'],   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensor] decomposition error: integer -1347300901 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -2384205769 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 339451904 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -16782712372 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -8896388413 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 280106447 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 60011317301 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 612286638 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 3510523750 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+-----------------+----------------+---------------+-----------------+----------------+------------------+---------------+-----------------+--------------------+--------------------+------------------------+\n",
      "| mean_error      | median_error   | max_error     | min_error       | mean_abs_error | median_abs_error | max_abs_error | min_abs_error   | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+-----------------+----------------+---------------+-----------------+----------------+------------------+---------------+-----------------+--------------------+--------------------+------------------------+\n",
      "| 0.0000019855797 | 0.000038832426 | 0.00005631894 | -0.000049181283 | 0.000027330965 | 0.000038832426   | 0.00005631894 | 0.0000053718686 | 0.0000000010372216 | -0.004466238       | 0.011762919            |\n",
      "+-----------------+----------------+---------------+-----------------+----------------+------------------+---------------+-----------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Settigns, calibration\n",
    "import ezkl\n",
    "import json \n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\" #Bob can see this\n",
    "py_run_args.output_visibility = \"public\" #This is also public as Bob needs to know the uncertainty\n",
    "py_run_args.param_visibility = \"private\" \n",
    "\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "assert res\n",
    "\n",
    "indices = random.sample(range(len(trainset)), 10)\n",
    "cal_images = np.array([trainset[i][0].numpy() for i in indices])\n",
    "\n",
    "#Alice should use some real data to calibrate the model, here we use random data\n",
    "data_array = (cal_images).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res \n",
    "\n",
    "# srs path - This actually requires a trusted setup.\n",
    "res = await ezkl.get_srs(settings_path)\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the ZKP prove and verify process into one function for convenience\n",
    "import time\n",
    "\n",
    "def prove_and_verify(prover_input: torch.Tensor):\n",
    "    print(prover_input) # I do not know why, but this line avoided errors in verifying the proof\n",
    "    # Serialize the prover input into a file\n",
    "    data_array = prover_input.detach().numpy().reshape([-1]).tolist()\n",
    "    data = dict(input_data = [data_array])\n",
    "    json.dump(data, open(data_path, 'w'))\n",
    "    \n",
    "    # This simulates Alice running the model inference\n",
    "    modelZK.eval()\n",
    "    output = modelZK(prover_input)\n",
    "    print(output)\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    #Generate witness\n",
    "    res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert res\n",
    "    print(\"Done witness\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # Prove\n",
    "    res = ezkl.prove(witness_path, compiled_model_path, pk_path, proof_path, \"single\")\n",
    "    assert res\n",
    "    print(\"Done proving\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # Verify\n",
    "    res = ezkl.verify(proof_path, settings_path, vk_path)\n",
    "    assert res\n",
    "    print(\"Done verifying\")\n",
    "    return output.detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point index: 95, Distance: 15.554551124572754\n",
      "tensor([[[[-0.8588, -0.6000, -0.2000,  ..., -0.7412, -0.4667, -0.4196],\n",
      "          [-0.8039, -0.4745, -0.0745,  ..., -0.7255, -0.6235, -0.4902],\n",
      "          [-0.5922, -0.3647, -0.2000,  ..., -0.7490, -0.7647, -0.6392],\n",
      "          ...,\n",
      "          [ 0.6000,  0.3725,  0.6157,  ...,  0.4118,  0.5216,  0.6706],\n",
      "          [ 0.5294,  0.4353,  0.6392,  ...,  0.4824,  0.6314,  0.6314],\n",
      "          [ 0.5843,  0.3961,  0.3961,  ...,  0.4824,  0.6157,  0.4745]],\n",
      "\n",
      "         [[-0.8902, -0.6078, -0.1529,  ..., -0.6706, -0.3961, -0.3020],\n",
      "          [-0.8588, -0.5137, -0.1059,  ..., -0.6863, -0.5451, -0.3725],\n",
      "          [-0.6627, -0.4431, -0.3176,  ..., -0.7176, -0.6706, -0.5216],\n",
      "          ...,\n",
      "          [ 0.3569,  0.0824,  0.4353,  ...,  0.2863,  0.2784,  0.5843],\n",
      "          [ 0.0588, -0.0275,  0.3647,  ...,  0.1843,  0.2549,  0.4353],\n",
      "          [ 0.3255,  0.2784,  0.3647,  ...,  0.1922,  0.3961,  0.3569]],\n",
      "\n",
      "         [[-0.8902, -0.8039, -0.6941,  ..., -0.9059, -0.7647, -0.8118],\n",
      "          [-0.9608, -0.8431, -0.6392,  ..., -0.8824, -0.8275, -0.8196],\n",
      "          [-0.9216, -0.9137, -0.8118,  ..., -0.8824, -0.8980, -0.9059],\n",
      "          ...,\n",
      "          [-0.1686, -0.5059, -0.0980,  ..., -0.3098, -0.1843,  0.1451],\n",
      "          [-0.3255, -0.4980, -0.0902,  ..., -0.3333, -0.1765,  0.0275],\n",
      "          [-0.1059, -0.2784, -0.1373,  ..., -0.3333, -0.1137, -0.2235]]]])\n",
      "tensor([-0.0041], grad_fn=<NegBackward0>)\n",
      "Done witness\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done proving\n",
      "Done verifying\n",
      "Point index: 15, Distance: 15.8023042678833\n",
      "tensor([[[[-0.8980, -0.8980, -0.8980,  ..., -0.8902, -0.6314, -0.5294],\n",
      "          [-0.8980, -0.8980, -0.8980,  ..., -0.8902, -0.6392, -0.5294],\n",
      "          [-0.8980, -0.8980, -0.8980,  ..., -0.8902, -0.6314, -0.5216],\n",
      "          ...,\n",
      "          [ 0.2235,  0.2157,  0.2314,  ...,  0.3569,  0.2627,  0.3020],\n",
      "          [ 0.2392,  0.2784,  0.3333,  ...,  0.3490,  0.3333,  0.3255],\n",
      "          [ 0.2863,  0.2863,  0.3333,  ...,  0.4039,  0.3961,  0.3255]],\n",
      "\n",
      "         [[-0.8510, -0.8510, -0.8510,  ..., -0.8275, -0.6314, -0.5686],\n",
      "          [-0.8510, -0.8510, -0.8510,  ..., -0.8275, -0.6314, -0.5686],\n",
      "          [-0.8510, -0.8510, -0.8510,  ..., -0.8275, -0.6314, -0.5608],\n",
      "          ...,\n",
      "          [ 0.3020,  0.2941,  0.3098,  ...,  0.4667,  0.3804,  0.4196],\n",
      "          [ 0.3333,  0.3647,  0.4196,  ...,  0.4667,  0.4510,  0.4510],\n",
      "          [ 0.3725,  0.3725,  0.3961,  ...,  0.5059,  0.4980,  0.4431]],\n",
      "\n",
      "         [[-0.8824, -0.8824, -0.8824,  ..., -0.9137, -0.7647, -0.7333],\n",
      "          [-0.8824, -0.8824, -0.8824,  ..., -0.9137, -0.7647, -0.7412],\n",
      "          [-0.8824, -0.8824, -0.8824,  ..., -0.9137, -0.7647, -0.7412],\n",
      "          ...,\n",
      "          [ 0.3882,  0.3804,  0.3961,  ...,  0.5216,  0.4353,  0.4902],\n",
      "          [ 0.4275,  0.4588,  0.5137,  ...,  0.5216,  0.5059,  0.5216],\n",
      "          [ 0.4588,  0.4510,  0.4824,  ...,  0.5765,  0.5765,  0.5137]]]])\n",
      "tensor([-0.0025], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 43, Distance: 12.758268356323242\n",
      "tensor([[[[-0.0510, -0.0196,  0.0039,  ...,  0.0275,  0.0118, -0.0039],\n",
      "          [-0.0353, -0.0118,  0.0196,  ...,  0.0353,  0.0196,  0.0039],\n",
      "          [-0.0431, -0.0196,  0.0118,  ...,  0.0118,  0.0039, -0.0118],\n",
      "          ...,\n",
      "          [-0.2627, -0.2392, -0.2314,  ..., -0.0039, -0.0118, -0.0275],\n",
      "          [-0.2941, -0.2784, -0.2627,  ..., -0.0196, -0.0353, -0.0431],\n",
      "          [-0.3255, -0.3176, -0.3020,  ..., -0.0510, -0.0667, -0.0824]],\n",
      "\n",
      "         [[ 0.2078,  0.2314,  0.2706,  ...,  0.3098,  0.2941,  0.2706],\n",
      "          [ 0.2235,  0.2549,  0.2863,  ...,  0.3176,  0.3020,  0.2863],\n",
      "          [ 0.2157,  0.2471,  0.2784,  ...,  0.2941,  0.2863,  0.2627],\n",
      "          ...,\n",
      "          [-0.0196, -0.0039,  0.0118,  ...,  0.2471,  0.2314,  0.2157],\n",
      "          [-0.0510, -0.0353, -0.0196,  ...,  0.2235,  0.2078,  0.2000],\n",
      "          [-0.0902, -0.0745, -0.0588,  ...,  0.1922,  0.1765,  0.1608]],\n",
      "\n",
      "         [[-0.4118, -0.3882, -0.3804,  ..., -0.3647, -0.3882, -0.3882],\n",
      "          [-0.3961, -0.3804, -0.3725,  ..., -0.3647, -0.3804, -0.3882],\n",
      "          [-0.4118, -0.3882, -0.3804,  ..., -0.3804, -0.3882, -0.3961],\n",
      "          ...,\n",
      "          [-0.5451, -0.5294, -0.5294,  ..., -0.2784, -0.2941, -0.3098],\n",
      "          [-0.5608, -0.5451, -0.5451,  ..., -0.3020, -0.3176, -0.3255],\n",
      "          [-0.5922, -0.5765, -0.5608,  ..., -0.3333, -0.3412, -0.3569]]]])\n",
      "tensor([-0.0031], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 65, Distance: 14.58976936340332\n",
      "tensor([[[[ 0.0510,  0.1686,  0.1608,  ...,  0.4118,  0.3490,  0.2392],\n",
      "          [ 0.0353,  0.0588,  0.1216,  ...,  0.4431,  0.3176,  0.2627],\n",
      "          [ 0.0980,  0.0667,  0.1216,  ...,  0.3020,  0.2235,  0.3098],\n",
      "          ...,\n",
      "          [ 0.0039,  0.1216,  0.3176,  ...,  0.1608,  0.2784, -0.0431],\n",
      "          [ 0.1137,  0.1686,  0.3255,  ...,  0.3098,  0.3098, -0.0980],\n",
      "          [ 0.2078,  0.2078,  0.1373,  ...,  0.2627,  0.2549, -0.1137]],\n",
      "\n",
      "         [[ 0.2471,  0.3176,  0.3176,  ...,  0.4745,  0.4196,  0.3412],\n",
      "          [ 0.2314,  0.2314,  0.3255,  ...,  0.5059,  0.4039,  0.3647],\n",
      "          [ 0.2549,  0.2157,  0.3255,  ...,  0.3882,  0.3333,  0.3961],\n",
      "          ...,\n",
      "          [ 0.1137,  0.2157,  0.3333,  ...,  0.2941,  0.3725,  0.0980],\n",
      "          [ 0.2471,  0.2549,  0.3020,  ...,  0.3882,  0.4275,  0.0745],\n",
      "          [ 0.3490,  0.3490,  0.1922,  ...,  0.3725,  0.3804,  0.0588]],\n",
      "\n",
      "         [[-0.5137, -0.4745, -0.6000,  ..., -0.0980, -0.2235, -0.3098],\n",
      "          [-0.5216, -0.5608, -0.6627,  ..., -0.0902, -0.3098, -0.2941],\n",
      "          [-0.4824, -0.5216, -0.6784,  ..., -0.2784, -0.4353, -0.2314],\n",
      "          ...,\n",
      "          [-0.4980, -0.3725, -0.1294,  ..., -0.3333, -0.2392, -0.4745],\n",
      "          [-0.3804, -0.3647, -0.1373,  ..., -0.2863, -0.3020, -0.5451],\n",
      "          [-0.2392, -0.3412, -0.4118,  ..., -0.3412, -0.3490, -0.5059]]]])\n",
      "tensor([-0.0041], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 64, Distance: 17.706371307373047\n",
      "tensor([[[[0.6863, 0.6549, 0.6235,  ..., 0.5529, 0.5529, 0.5529],\n",
      "          [0.6784, 0.6471, 0.6235,  ..., 0.5294, 0.5373, 0.5451],\n",
      "          [0.6706, 0.6392, 0.6157,  ..., 0.5137, 0.5216, 0.5373],\n",
      "          ...,\n",
      "          [0.2000, 0.1608, 0.0902,  ..., 0.0745, 0.0980, 0.0980],\n",
      "          [0.1216, 0.0902, 0.1137,  ..., 0.0353, 0.0745, 0.0431],\n",
      "          [0.1294, 0.0980, 0.1216,  ..., 0.0353, 0.0431, 0.0118]],\n",
      "\n",
      "         [[0.6941, 0.6549, 0.6235,  ..., 0.4980, 0.4980, 0.4980],\n",
      "          [0.6784, 0.6471, 0.6235,  ..., 0.4745, 0.4824, 0.4902],\n",
      "          [0.6627, 0.6235, 0.6000,  ..., 0.4588, 0.4667, 0.4824],\n",
      "          ...,\n",
      "          [0.2549, 0.2157, 0.1294,  ..., 0.0667, 0.1059, 0.1059],\n",
      "          [0.1765, 0.1451, 0.1529,  ..., 0.0510, 0.0824, 0.0510],\n",
      "          [0.2000, 0.1608, 0.1686,  ..., 0.0431, 0.0353, 0.0118]],\n",
      "\n",
      "         [[0.7333, 0.6863, 0.6314,  ..., 0.4275, 0.4353, 0.4431],\n",
      "          [0.7176, 0.6627, 0.6235,  ..., 0.3961, 0.4118, 0.4353],\n",
      "          [0.6941, 0.6392, 0.6000,  ..., 0.3804, 0.3961, 0.4196],\n",
      "          ...,\n",
      "          [0.3255, 0.2627, 0.1765,  ..., 0.0588, 0.1216, 0.1137],\n",
      "          [0.2471, 0.1922, 0.2000,  ..., 0.0353, 0.0824, 0.0588],\n",
      "          [0.2627, 0.2078, 0.2157,  ..., 0.0353, 0.0196, 0.0118]]]])\n",
      "tensor([-0.0018], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 27, Distance: 19.004453659057617\n",
      "tensor([[[[0.7725, 0.7255, 0.7098,  ..., 0.7725, 0.8353, 0.8980],\n",
      "          [0.7490, 0.6941, 0.6941,  ..., 0.8196, 0.8824, 0.9608],\n",
      "          [0.7412, 0.6863, 0.7098,  ..., 0.8510, 0.9059, 0.9608],\n",
      "          ...,\n",
      "          [0.7961, 0.7490, 0.7098,  ..., 0.6314, 0.6549, 0.6706],\n",
      "          [0.8275, 0.7804, 0.7176,  ..., 0.6863, 0.6863, 0.7020],\n",
      "          [0.8824, 0.8275, 0.7725,  ..., 0.7647, 0.7569, 0.7647]],\n",
      "\n",
      "         [[0.8824, 0.8196, 0.8039,  ..., 0.8510, 0.8824, 0.9137],\n",
      "          [0.8431, 0.7882, 0.7961,  ..., 0.8824, 0.9216, 0.9686],\n",
      "          [0.8353, 0.7804, 0.8039,  ..., 0.8824, 0.9216, 0.9686],\n",
      "          ...,\n",
      "          [0.7882, 0.7098, 0.6549,  ..., 0.6235, 0.6471, 0.6627],\n",
      "          [0.8196, 0.7412, 0.6627,  ..., 0.6706, 0.6706, 0.6863],\n",
      "          [0.8667, 0.7961, 0.7176,  ..., 0.7412, 0.7333, 0.7412]],\n",
      "\n",
      "         [[0.9216, 0.8902, 0.9059,  ..., 0.9137, 0.8980, 0.8902],\n",
      "          [0.9451, 0.8902, 0.8902,  ..., 0.9608, 0.9608, 0.9608],\n",
      "          [0.9765, 0.9059, 0.9216,  ..., 0.9765, 0.9843, 0.9922],\n",
      "          ...,\n",
      "          [0.7569, 0.6941, 0.6392,  ..., 0.6392, 0.6627, 0.6784],\n",
      "          [0.7882, 0.7176, 0.6392,  ..., 0.6549, 0.6549, 0.6706],\n",
      "          [0.8275, 0.7569, 0.6863,  ..., 0.7098, 0.7020, 0.7098]]]])\n",
      "tensor([-0.0036], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 87, Distance: 17.271434783935547\n",
      "tensor([[[[ 0.2314,  0.1686,  0.1294,  ...,  0.2078,  0.2314,  0.2392],\n",
      "          [ 0.2235,  0.2000,  0.1922,  ...,  0.1451,  0.1608,  0.1765],\n",
      "          [ 0.2314,  0.2549,  0.2549,  ...,  0.1843,  0.1843,  0.1922],\n",
      "          ...,\n",
      "          [-0.0510, -0.0667, -0.1216,  ...,  0.2000,  0.2157,  0.2392],\n",
      "          [-0.0510, -0.0196, -0.0431,  ...,  0.2784,  0.3569,  0.3569],\n",
      "          [-0.1451, -0.1294, -0.1294,  ...,  0.3255,  0.2078,  0.2549]],\n",
      "\n",
      "         [[ 0.3647,  0.3098,  0.2627,  ...,  0.3490,  0.3569,  0.3725],\n",
      "          [ 0.3412,  0.3255,  0.3176,  ...,  0.2784,  0.2863,  0.3020],\n",
      "          [ 0.3412,  0.3647,  0.3647,  ...,  0.3098,  0.3098,  0.3255],\n",
      "          ...,\n",
      "          [-0.0431, -0.0431, -0.0980,  ...,  0.1922,  0.1922,  0.1922],\n",
      "          [-0.0196,  0.0039, -0.0196,  ...,  0.2235,  0.2706,  0.2471],\n",
      "          [-0.1216, -0.1059, -0.1059,  ...,  0.2000,  0.0824,  0.1373]],\n",
      "\n",
      "         [[ 0.4745,  0.4275,  0.3882,  ...,  0.4431,  0.4588,  0.4510],\n",
      "          [ 0.4431,  0.4275,  0.4275,  ...,  0.3725,  0.3804,  0.3961],\n",
      "          [ 0.4275,  0.4510,  0.4510,  ...,  0.3961,  0.4039,  0.4196],\n",
      "          ...,\n",
      "          [-0.0667, -0.0667, -0.1216,  ...,  0.0824,  0.0667,  0.0431],\n",
      "          [-0.0510, -0.0275, -0.0510,  ...,  0.0431,  0.0667,  0.0275],\n",
      "          [-0.1373, -0.1294, -0.1294,  ..., -0.0275, -0.1608, -0.1137]]]])\n",
      "tensor([-0.0026], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 59, Distance: 17.563451766967773\n",
      "tensor([[[[ 0.8588,  0.8275,  0.8353,  ...,  0.9294,  0.9451,  0.9373],\n",
      "          [ 0.7020,  0.6784,  0.6941,  ...,  0.9059,  0.9216,  0.9294],\n",
      "          [ 0.4667,  0.4510,  0.4667,  ...,  0.8118,  0.8275,  0.8353],\n",
      "          ...,\n",
      "          [ 0.8588,  0.6314,  0.2314,  ..., -0.1608, -0.1294, -0.1137],\n",
      "          [ 0.8588,  0.6078,  0.0275,  ...,  0.0118, -0.0118, -0.0196],\n",
      "          [ 0.8667,  0.7020,  0.3647,  ...,  0.0039,  0.1451,  0.0745]],\n",
      "\n",
      "         [[ 0.8510,  0.8275,  0.8353,  ...,  0.9216,  0.9373,  0.9216],\n",
      "          [ 0.7333,  0.7098,  0.7255,  ...,  0.8980,  0.9137,  0.9137],\n",
      "          [ 0.5686,  0.5451,  0.5608,  ...,  0.8118,  0.8196,  0.8275],\n",
      "          ...,\n",
      "          [ 0.8431,  0.6314,  0.2392,  ..., -0.0118,  0.0039,  0.0118],\n",
      "          [ 0.8510,  0.6078,  0.0275,  ...,  0.1608,  0.1294,  0.1059],\n",
      "          [ 0.8588,  0.7020,  0.3647,  ...,  0.1451,  0.2863,  0.2078]],\n",
      "\n",
      "         [[ 0.8510,  0.8039,  0.8039,  ...,  0.9059,  0.9216,  0.9294],\n",
      "          [ 0.7255,  0.6941,  0.7098,  ...,  0.8824,  0.9059,  0.9216],\n",
      "          [ 0.5529,  0.5451,  0.5529,  ...,  0.7961,  0.8039,  0.8196],\n",
      "          ...,\n",
      "          [ 0.8275,  0.6392,  0.2471,  ...,  0.1059,  0.1294,  0.1373],\n",
      "          [ 0.8353,  0.6000,  0.0275,  ...,  0.2314,  0.2078,  0.1843],\n",
      "          [ 0.8431,  0.6941,  0.3647,  ...,  0.2157,  0.3569,  0.2863]]]])\n",
      "tensor([-0.0030], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 93, Distance: 14.363693237304688\n",
      "tensor([[[[-0.6784, -0.6549, -0.6706,  ..., -0.4980, -0.4980, -0.5216],\n",
      "          [-0.6941, -0.7020, -0.7098,  ..., -0.5843, -0.5451, -0.5059],\n",
      "          [-0.7804, -0.7647, -0.7490,  ..., -0.5451, -0.5294, -0.5137],\n",
      "          ...,\n",
      "          [-0.8745, -0.8431, -0.8588,  ..., -0.8824, -0.8902, -0.9059],\n",
      "          [-0.8745, -0.8902, -0.8745,  ..., -0.9059, -0.8824, -0.9059],\n",
      "          [-0.8902, -0.8745, -0.9059,  ..., -0.8824, -0.8824, -0.8824]],\n",
      "\n",
      "         [[-0.5216, -0.5059, -0.5216,  ..., -0.4275, -0.4431, -0.4588],\n",
      "          [-0.5294, -0.5451, -0.5608,  ..., -0.5216, -0.4824, -0.4431],\n",
      "          [-0.6157, -0.6078, -0.5922,  ..., -0.4745, -0.4667, -0.4510],\n",
      "          ...,\n",
      "          [-0.8275, -0.7961, -0.8118,  ..., -0.8275, -0.8353, -0.8510],\n",
      "          [-0.8118, -0.8275, -0.8196,  ..., -0.8431, -0.8196, -0.8431],\n",
      "          [-0.8039, -0.7961, -0.8196,  ..., -0.8196, -0.8196, -0.8196]],\n",
      "\n",
      "         [[-0.3176, -0.2706, -0.2627,  ..., -0.3412, -0.3569, -0.3725],\n",
      "          [-0.3412, -0.3255, -0.3176,  ..., -0.4353, -0.3961, -0.3569],\n",
      "          [-0.4431, -0.4196, -0.3804,  ..., -0.3882, -0.3804, -0.3647],\n",
      "          ...,\n",
      "          [-0.6941, -0.6706, -0.6863,  ..., -0.6941, -0.7020, -0.7176],\n",
      "          [-0.6549, -0.6706, -0.6549,  ..., -0.7333, -0.7098, -0.7333],\n",
      "          [-0.6627, -0.6549, -0.6784,  ..., -0.7255, -0.7333, -0.7255]]]])\n",
      "tensor([-0.0037], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 99, Distance: 14.454360961914062\n",
      "tensor([[[[-0.8588, -0.8196, -0.7569,  ..., -0.8824, -0.8667, -0.8667],\n",
      "          [-0.7569, -0.7569, -0.7569,  ..., -0.8275, -0.8431, -0.8510],\n",
      "          [-0.6784, -0.6549, -0.6627,  ..., -0.7725, -0.7961, -0.8118],\n",
      "          ...,\n",
      "          [-0.7020, -0.6863, -0.6784,  ..., -0.6157, -0.6314, -0.6235],\n",
      "          [-0.7020, -0.6863, -0.6863,  ..., -0.6235, -0.6471, -0.6627],\n",
      "          [-0.7412, -0.7176, -0.7098,  ..., -0.6784, -0.6863, -0.6863]],\n",
      "\n",
      "         [[-0.8745, -0.8353, -0.7725,  ..., -0.9137, -0.8902, -0.8980],\n",
      "          [-0.7725, -0.7725, -0.7647,  ..., -0.8980, -0.8980, -0.9059],\n",
      "          [-0.7490, -0.7255, -0.7412,  ..., -0.8667, -0.8745, -0.8902],\n",
      "          ...,\n",
      "          [-0.8039, -0.7882, -0.7804,  ..., -0.7882, -0.7804, -0.7725],\n",
      "          [-0.7961, -0.7882, -0.7804,  ..., -0.7804, -0.7804, -0.7882],\n",
      "          [-0.8196, -0.8118, -0.8118,  ..., -0.7961, -0.7804, -0.7804]],\n",
      "\n",
      "         [[-0.8902, -0.8510, -0.7882,  ..., -0.8980, -0.8902, -0.8902],\n",
      "          [-0.7804, -0.7804, -0.7804,  ..., -0.9137, -0.9059, -0.9137],\n",
      "          [-0.8118, -0.7882, -0.7961,  ..., -0.9059, -0.8980, -0.9059],\n",
      "          ...,\n",
      "          [-0.8510, -0.8588, -0.8510,  ..., -0.8980, -0.8824, -0.8824],\n",
      "          [-0.8510, -0.8510, -0.8588,  ..., -0.9059, -0.9059, -0.9216],\n",
      "          [-0.8824, -0.8824, -0.8902,  ..., -0.9451, -0.9529, -0.9451]]]])\n",
      "tensor([-0.0044], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 83, Distance: 12.731120109558105\n",
      "tensor([[[[ 0.3020,  0.3020,  0.3176,  ...,  0.2471,  0.1294,  0.0980],\n",
      "          [ 0.1608,  0.1922,  0.2235,  ...,  0.1373,  0.1373,  0.0824],\n",
      "          [ 0.1373,  0.1216,  0.1373,  ...,  0.0667,  0.1843,  0.1137],\n",
      "          ...,\n",
      "          [-0.0118, -0.2392, -0.2000,  ...,  0.2000, -0.0118,  0.0431],\n",
      "          [-0.0902, -0.2784, -0.2392,  ...,  0.0824, -0.0980, -0.0275],\n",
      "          [-0.1373, -0.2235, -0.1843,  ..., -0.0510, -0.0902, -0.0196]],\n",
      "\n",
      "         [[ 0.3020,  0.3020,  0.3176,  ...,  0.2471,  0.1294,  0.0980],\n",
      "          [ 0.1608,  0.1922,  0.2235,  ...,  0.1373,  0.1373,  0.0824],\n",
      "          [ 0.1373,  0.1216,  0.1373,  ...,  0.0667,  0.1843,  0.1137],\n",
      "          ...,\n",
      "          [-0.0118, -0.2392, -0.2000,  ...,  0.2000, -0.0118,  0.0431],\n",
      "          [-0.0902, -0.2784, -0.2392,  ...,  0.0824, -0.0980, -0.0275],\n",
      "          [-0.1373, -0.2235, -0.1843,  ..., -0.0510, -0.0902, -0.0196]],\n",
      "\n",
      "         [[ 0.3020,  0.3020,  0.3176,  ...,  0.2471,  0.1294,  0.0980],\n",
      "          [ 0.1608,  0.1922,  0.2235,  ...,  0.1373,  0.1373,  0.0824],\n",
      "          [ 0.1373,  0.1216,  0.1373,  ...,  0.0667,  0.1843,  0.1137],\n",
      "          ...,\n",
      "          [-0.0118, -0.2392, -0.2000,  ...,  0.2000, -0.0118,  0.0431],\n",
      "          [-0.0902, -0.2784, -0.2392,  ...,  0.0824, -0.0980, -0.0275],\n",
      "          [-0.1373, -0.2235, -0.1843,  ..., -0.0510, -0.0902, -0.0196]]]])\n",
      "tensor([-0.0040], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 74, Distance: 15.98022174835205\n",
      "tensor([[[[0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
      "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
      "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
      "          ...,\n",
      "          [0.1373, 0.1373, 0.1451,  ..., 0.1451, 0.1373, 0.1373],\n",
      "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
      "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373]],\n",
      "\n",
      "         [[0.2235, 0.2235, 0.2235,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          [0.2235, 0.2235, 0.2235,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          [0.2235, 0.2235, 0.2235,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          ...,\n",
      "          [0.2235, 0.2235, 0.2314,  ..., 0.2392, 0.2314, 0.2314],\n",
      "          [0.2235, 0.2235, 0.2235,  ..., 0.2314, 0.2314, 0.2314],\n",
      "          [0.2235, 0.2235, 0.2235,  ..., 0.2314, 0.2314, 0.2314]],\n",
      "\n",
      "         [[0.2392, 0.2392, 0.2392,  ..., 0.2392, 0.2392, 0.2392],\n",
      "          [0.2392, 0.2392, 0.2392,  ..., 0.2392, 0.2392, 0.2392],\n",
      "          [0.2392, 0.2392, 0.2392,  ..., 0.2392, 0.2392, 0.2392],\n",
      "          ...,\n",
      "          [0.2392, 0.2392, 0.2471,  ..., 0.2235, 0.2157, 0.2157],\n",
      "          [0.2392, 0.2392, 0.2392,  ..., 0.2000, 0.2078, 0.2157],\n",
      "          [0.2392, 0.2392, 0.2392,  ..., 0.2235, 0.2235, 0.2314]]]])\n",
      "tensor([-0.0029], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 77, Distance: 17.10785675048828\n",
      "tensor([[[[ 0.2314,  0.1373,  0.0824,  ...,  0.0275, -0.0980,  0.0588],\n",
      "          [ 0.2078,  0.1765,  0.1686,  ...,  0.0667, -0.0118,  0.1451],\n",
      "          [ 0.4196,  0.2471,  0.0980,  ...,  0.2471,  0.2078,  0.2471],\n",
      "          ...,\n",
      "          [ 0.8275,  0.8510,  0.8510,  ...,  0.3725,  0.3882,  0.4275],\n",
      "          [ 0.8588,  0.7804,  0.6706,  ...,  0.3725,  0.3569,  0.3725],\n",
      "          [ 0.7490,  0.7333,  0.6078,  ...,  0.3020,  0.2941,  0.3255]],\n",
      "\n",
      "         [[ 0.2314,  0.1373,  0.0824,  ...,  0.0275, -0.0980,  0.0588],\n",
      "          [ 0.2078,  0.1765,  0.1686,  ...,  0.0667, -0.0118,  0.1451],\n",
      "          [ 0.4196,  0.2471,  0.0980,  ...,  0.2471,  0.2078,  0.2471],\n",
      "          ...,\n",
      "          [ 0.8275,  0.8510,  0.8510,  ...,  0.3725,  0.3882,  0.4275],\n",
      "          [ 0.8588,  0.7804,  0.6706,  ...,  0.3725,  0.3569,  0.3725],\n",
      "          [ 0.7490,  0.7333,  0.6078,  ...,  0.3020,  0.2941,  0.3255]],\n",
      "\n",
      "         [[ 0.2314,  0.1373,  0.0824,  ...,  0.0275, -0.0980,  0.0588],\n",
      "          [ 0.2078,  0.1765,  0.1686,  ...,  0.0667, -0.0118,  0.1451],\n",
      "          [ 0.4196,  0.2471,  0.0980,  ...,  0.2471,  0.2078,  0.2471],\n",
      "          ...,\n",
      "          [ 0.8275,  0.8510,  0.8510,  ...,  0.3725,  0.3882,  0.4275],\n",
      "          [ 0.8588,  0.7804,  0.6706,  ...,  0.3725,  0.3569,  0.3725],\n",
      "          [ 0.7490,  0.7333,  0.6078,  ...,  0.3020,  0.2941,  0.3255]]]])\n",
      "tensor([-0.0033], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 82, Distance: 17.294897079467773\n",
      "tensor([[[[ 0.3255,  0.3020,  0.3176,  ...,  0.0510,  0.1137,  0.1608],\n",
      "          [ 0.2157,  0.2078,  0.2078,  ...,  0.1451,  0.1373,  0.1765],\n",
      "          [ 0.1529,  0.1922,  0.1608,  ...,  0.0588,  0.1529,  0.1922],\n",
      "          ...,\n",
      "          [ 0.3882,  0.3804,  0.3412,  ...,  0.0275,  0.0510,  0.0745],\n",
      "          [ 0.3333,  0.3804,  0.3804,  ..., -0.0196, -0.0588, -0.0902],\n",
      "          [ 0.3255,  0.2784,  0.3647,  ..., -0.1373, -0.0980, -0.0902]],\n",
      "\n",
      "         [[ 0.5608,  0.5451,  0.5529,  ...,  0.2314,  0.3020,  0.3569],\n",
      "          [ 0.4980,  0.4824,  0.4824,  ...,  0.3569,  0.2627,  0.2863],\n",
      "          [ 0.4588,  0.4980,  0.4667,  ...,  0.2941,  0.2941,  0.3098],\n",
      "          ...,\n",
      "          [ 0.1294,  0.1451,  0.1216,  ...,  0.0980,  0.0667,  0.0824],\n",
      "          [ 0.0745,  0.1294,  0.1608,  ...,  0.1059,  0.0118, -0.0353],\n",
      "          [ 0.0745,  0.0431,  0.1373,  ...,  0.0431,  0.0510,  0.0510]],\n",
      "\n",
      "         [[ 0.1137,  0.0980,  0.1137,  ..., -0.1765, -0.0353,  0.0196],\n",
      "          [ 0.0510,  0.0353,  0.0353,  ..., -0.0980, -0.0824, -0.0275],\n",
      "          [ 0.0196,  0.0588,  0.0275,  ..., -0.1059, -0.0510, -0.0118],\n",
      "          ...,\n",
      "          [ 0.0196,  0.0588,  0.0510,  ...,  0.0196, -0.0353, -0.0275],\n",
      "          [-0.0431,  0.0353,  0.0745,  ...,  0.0118, -0.1059, -0.1608],\n",
      "          [-0.0118, -0.0431,  0.0588,  ..., -0.1294, -0.1216, -0.1216]]]])\n",
      "tensor([-0.0035], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 58, Distance: 11.684380531311035\n",
      "tensor([[[[-0.4039, -0.2863, -0.2392,  ..., -0.5137, -0.5765, -0.5922],\n",
      "          [-0.3333, -0.2235, -0.2941,  ..., -0.3804, -0.5137, -0.5922],\n",
      "          [-0.2784, -0.2000, -0.3176,  ..., -0.3569, -0.3804, -0.5216],\n",
      "          ...,\n",
      "          [-0.3961, -0.3333, -0.3882,  ..., -0.1686, -0.3647, -0.4118],\n",
      "          [-0.3804, -0.3020, -0.2706,  ..., -0.2627, -0.3725, -0.4431],\n",
      "          [-0.2784, -0.2627, -0.2235,  ..., -0.3098, -0.3725, -0.4431]],\n",
      "\n",
      "         [[-0.3255, -0.2078, -0.1608,  ..., -0.4353, -0.4980, -0.5294],\n",
      "          [-0.2549, -0.1451, -0.2157,  ..., -0.3020, -0.4353, -0.5294],\n",
      "          [-0.2000, -0.1216, -0.2392,  ..., -0.2784, -0.3020, -0.4510],\n",
      "          ...,\n",
      "          [-0.2706, -0.2078, -0.2627,  ..., -0.1059, -0.2784, -0.3098],\n",
      "          [-0.2627, -0.1843, -0.1529,  ..., -0.2000, -0.2784, -0.3412],\n",
      "          [-0.1922, -0.1686, -0.1373,  ..., -0.2549, -0.2941, -0.3490]],\n",
      "\n",
      "         [[-0.3333, -0.2157, -0.1686,  ..., -0.4431, -0.5059, -0.5294],\n",
      "          [-0.2627, -0.1529, -0.2235,  ..., -0.3098, -0.4431, -0.5294],\n",
      "          [-0.2078, -0.1294, -0.2471,  ..., -0.2863, -0.3098, -0.4588],\n",
      "          ...,\n",
      "          [-0.2941, -0.2314, -0.2863,  ..., -0.0824, -0.2627, -0.3020],\n",
      "          [-0.2863, -0.2078, -0.1765,  ..., -0.1765, -0.2627, -0.3333],\n",
      "          [-0.2000, -0.1765, -0.1451,  ..., -0.2235, -0.2784, -0.3412]]]])\n",
      "tensor([-0.0034], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 72, Distance: 12.996651649475098\n",
      "tensor([[[[-0.4902, -0.4196, -0.3725,  ..., -0.3255, -0.2392, -0.2706],\n",
      "          [-0.4588, -0.3255, -0.2235,  ..., -0.4353, -0.4039, -0.4353],\n",
      "          [-0.4196, -0.3725, -0.3804,  ..., -0.5059, -0.5137, -0.5451],\n",
      "          ...,\n",
      "          [-0.2314, -0.3255, -0.4353,  ..., -0.7020, -0.5922, -0.3961],\n",
      "          [-0.1922, -0.2627, -0.3020,  ..., -0.5294, -0.6784, -0.6157],\n",
      "          [-0.0745, -0.2000, -0.2392,  ..., -0.5529, -0.6314, -0.7176]],\n",
      "\n",
      "         [[-0.3020, -0.2471, -0.1922,  ..., -0.1451, -0.0667, -0.0902],\n",
      "          [-0.2706, -0.1294, -0.0353,  ..., -0.2314, -0.2000, -0.2314],\n",
      "          [-0.2235, -0.1765, -0.1843,  ..., -0.2706, -0.2784, -0.3098],\n",
      "          ...,\n",
      "          [ 0.0039, -0.0902, -0.2000,  ..., -0.5137, -0.4039, -0.2078],\n",
      "          [ 0.0431, -0.0275, -0.0667,  ..., -0.3255, -0.4745, -0.4196],\n",
      "          [ 0.1608,  0.0353, -0.0039,  ..., -0.3333, -0.4196, -0.5137]],\n",
      "\n",
      "         [[-0.4196, -0.3804, -0.3569,  ..., -0.3961, -0.3098, -0.3412],\n",
      "          [-0.4039, -0.2863, -0.2078,  ..., -0.4510, -0.4196, -0.4588],\n",
      "          [-0.3804, -0.3490, -0.3647,  ..., -0.4667, -0.4745, -0.4980],\n",
      "          ...,\n",
      "          [-0.0745, -0.1686, -0.2784,  ..., -0.5922, -0.4980, -0.3176],\n",
      "          [-0.0353, -0.1059, -0.1451,  ..., -0.4118, -0.5765, -0.5216],\n",
      "          [ 0.0824, -0.0431, -0.0824,  ..., -0.4275, -0.5137, -0.6157]]]])\n",
      "tensor([-0.0040], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 44, Distance: 17.255542755126953\n",
      "tensor([[[[0.4667, 0.4196, 0.4039,  ..., 0.3490, 0.3333, 0.3098],\n",
      "          [0.4745, 0.4196, 0.4039,  ..., 0.3333, 0.3176, 0.2863],\n",
      "          [0.4667, 0.4118, 0.4039,  ..., 0.3255, 0.3098, 0.2784],\n",
      "          ...,\n",
      "          [0.3725, 0.3020, 0.2941,  ..., 0.1608, 0.1608, 0.1529],\n",
      "          [0.3804, 0.3098, 0.3020,  ..., 0.1529, 0.1608, 0.1529],\n",
      "          [0.3961, 0.3333, 0.3176,  ..., 0.1294, 0.1451, 0.1529]],\n",
      "\n",
      "         [[0.7098, 0.6549, 0.6314,  ..., 0.4667, 0.4431, 0.4196],\n",
      "          [0.7176, 0.6549, 0.6392,  ..., 0.4510, 0.4275, 0.3961],\n",
      "          [0.7098, 0.6471, 0.6314,  ..., 0.4431, 0.4196, 0.3882],\n",
      "          ...,\n",
      "          [0.6392, 0.5686, 0.5529,  ..., 0.3255, 0.3176, 0.3176],\n",
      "          [0.6392, 0.5686, 0.5529,  ..., 0.3333, 0.3333, 0.3176],\n",
      "          [0.6314, 0.5608, 0.5451,  ..., 0.3490, 0.3412, 0.3255]],\n",
      "\n",
      "         [[0.8824, 0.8510, 0.8588,  ..., 0.7490, 0.7333, 0.7098],\n",
      "          [0.8902, 0.8588, 0.8667,  ..., 0.7412, 0.7176, 0.6863],\n",
      "          [0.8824, 0.8510, 0.8588,  ..., 0.7333, 0.7098, 0.6784],\n",
      "          ...,\n",
      "          [0.8353, 0.7804, 0.7961,  ..., 0.6784, 0.6784, 0.6784],\n",
      "          [0.8275, 0.7804, 0.7882,  ..., 0.6784, 0.6784, 0.6706],\n",
      "          [0.8353, 0.7961, 0.7961,  ..., 0.6627, 0.6627, 0.6549]]]])\n",
      "tensor([-0.0020], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 20, Distance: 17.286867141723633\n",
      "tensor([[[[0.7020, 0.6706, 0.6706,  ..., 0.6627, 0.6392, 0.6392],\n",
      "          [0.7176, 0.6863, 0.6941,  ..., 0.7020, 0.6706, 0.6706],\n",
      "          [0.7020, 0.6784, 0.6784,  ..., 0.7098, 0.6784, 0.6627],\n",
      "          ...,\n",
      "          [0.7098, 0.7020, 0.6941,  ..., 0.6549, 0.6549, 0.6549],\n",
      "          [0.7176, 0.7176, 0.7176,  ..., 0.7020, 0.6784, 0.6627],\n",
      "          [0.7333, 0.7255, 0.7176,  ..., 0.6941, 0.6863, 0.6706]],\n",
      "\n",
      "         [[0.6549, 0.6235, 0.6235,  ..., 0.6549, 0.6314, 0.6235],\n",
      "          [0.6706, 0.6392, 0.6471,  ..., 0.6706, 0.6471, 0.6392],\n",
      "          [0.6549, 0.6314, 0.6314,  ..., 0.6627, 0.6235, 0.6078],\n",
      "          ...,\n",
      "          [0.7255, 0.7176, 0.7098,  ..., 0.6627, 0.6627, 0.6627],\n",
      "          [0.7333, 0.7333, 0.7333,  ..., 0.7098, 0.6863, 0.6706],\n",
      "          [0.7412, 0.7412, 0.7333,  ..., 0.7020, 0.6941, 0.6784]],\n",
      "\n",
      "         [[0.5294, 0.4980, 0.4980,  ..., 0.6157, 0.5922, 0.5843],\n",
      "          [0.5373, 0.5137, 0.5216,  ..., 0.6392, 0.6078, 0.6078],\n",
      "          [0.5216, 0.5059, 0.5059,  ..., 0.6314, 0.6000, 0.5843],\n",
      "          ...,\n",
      "          [0.6392, 0.6314, 0.6235,  ..., 0.6235, 0.6235, 0.6235],\n",
      "          [0.6471, 0.6471, 0.6471,  ..., 0.6706, 0.6471, 0.6314],\n",
      "          [0.6627, 0.6549, 0.6549,  ..., 0.6627, 0.6549, 0.6392]]]])\n",
      "tensor([-0.0005], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 86, Distance: 13.713028907775879\n",
      "tensor([[[[-0.4980, -0.5059, -0.5608,  ..., -0.2157, -0.2549, -0.2784],\n",
      "          [-0.4039, -0.2706, -0.3882,  ..., -0.1922, -0.2627, -0.2549],\n",
      "          [-0.2549, -0.1529, -0.2000,  ..., -0.1686, -0.2471, -0.2314],\n",
      "          ...,\n",
      "          [-0.6078, -0.5451, -0.5294,  ..., -0.6627, -0.6627, -0.5373],\n",
      "          [-0.6000, -0.5922, -0.5843,  ..., -0.5765, -0.6863, -0.7176],\n",
      "          [-0.6314, -0.5686, -0.5451,  ..., -0.5686, -0.6392, -0.6784]],\n",
      "\n",
      "         [[-0.5373, -0.5529, -0.4824,  ..., -0.4275, -0.5216, -0.5137],\n",
      "          [-0.6392, -0.6471, -0.5216,  ..., -0.4275, -0.5059, -0.4667],\n",
      "          [-0.5294, -0.6314, -0.5216,  ..., -0.4196, -0.4667, -0.4196],\n",
      "          ...,\n",
      "          [-0.2863, -0.2314, -0.2078,  ..., -0.2784, -0.3020, -0.2000],\n",
      "          [-0.2784, -0.2784, -0.2627,  ..., -0.1922, -0.3255, -0.3804],\n",
      "          [-0.3569, -0.2941, -0.2784,  ..., -0.2471, -0.3255, -0.3961]],\n",
      "\n",
      "         [[-0.4275, -0.3882, -0.3020,  ..., -0.2941, -0.3725, -0.3725],\n",
      "          [-0.4824, -0.4039, -0.3333,  ..., -0.2784, -0.3647, -0.3333],\n",
      "          [-0.3882, -0.3961, -0.3333,  ..., -0.2706, -0.3333, -0.2941],\n",
      "          ...,\n",
      "          [-0.1216, -0.0667, -0.0510,  ..., -0.1059, -0.1373, -0.0588],\n",
      "          [-0.1137, -0.1216, -0.1059,  ..., -0.0431, -0.1843, -0.2627],\n",
      "          [-0.2314, -0.1765, -0.1529,  ..., -0.0980, -0.1922, -0.2784]]]])\n",
      "tensor([-0.0033], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n",
      "Point index: 55, Distance: 13.915383338928223\n",
      "tensor([[[[-0.1765, -0.2078, -0.2235,  ...,  0.0667,  0.0510,  0.0902],\n",
      "          [-0.1137, -0.0902, -0.0980,  ...,  0.1765,  0.1922,  0.2157],\n",
      "          [-0.1608, -0.1451, -0.0824,  ...,  0.0275,  0.0431,  0.0510],\n",
      "          ...,\n",
      "          [ 0.0745,  0.0745,  0.0510,  ..., -0.0980, -0.1373, -0.1373],\n",
      "          [ 0.0980, -0.0353, -0.0275,  ..., -0.1922, -0.2314, -0.1843],\n",
      "          [ 0.0745,  0.0431,  0.0275,  ..., -0.2314, -0.2392, -0.1137]],\n",
      "\n",
      "         [[-0.0902, -0.1216, -0.1294,  ...,  0.1451,  0.1216,  0.1529],\n",
      "          [-0.0118,  0.0118,  0.0039,  ...,  0.2235,  0.2157,  0.2314],\n",
      "          [-0.0510, -0.0431,  0.0196,  ...,  0.0667,  0.0824,  0.0902],\n",
      "          ...,\n",
      "          [ 0.0275,  0.0275,  0.0039,  ..., -0.1373, -0.1843, -0.1843],\n",
      "          [ 0.0588, -0.0824, -0.0745,  ..., -0.2392, -0.2706, -0.2235],\n",
      "          [ 0.0196, -0.0039, -0.0196,  ..., -0.2784, -0.2863, -0.1529]],\n",
      "\n",
      "         [[-0.4275, -0.4510, -0.4667,  ..., -0.2078, -0.2627, -0.2549],\n",
      "          [-0.4353, -0.4118, -0.4039,  ..., -0.0667, -0.1059, -0.1059],\n",
      "          [-0.5216, -0.4902, -0.4039,  ..., -0.2549, -0.2706, -0.2784],\n",
      "          ...,\n",
      "          [-0.1451, -0.1529, -0.1686,  ..., -0.3098, -0.3569, -0.3647],\n",
      "          [-0.1451, -0.2863, -0.2706,  ..., -0.4196, -0.4824, -0.4510],\n",
      "          [-0.1843, -0.2157, -0.2314,  ..., -0.4588, -0.4902, -0.3804]]]])\n",
      "tensor([-0.0033], grad_fn=<NegBackward0>)\n",
      "Done witness\n",
      "Done proving\n",
      "Done verifying\n"
     ]
    }
   ],
   "source": [
    "TOTAL_BUDGET = 20 #This means maximum of 3 queries per cluster\n",
    "budget = TOTAL_BUDGET // K\n",
    "# Loop through each cluster\n",
    "points_to_submit = []\n",
    "labels_to_submit = []\n",
    "for cluster_idx in range(K):\n",
    "    # Get the indices of points in the current cluster\n",
    "    cluster_points_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "    \n",
    "    # Get the points in the current cluster\n",
    "    cluster_points = flattened_images[cluster_points_indices]\n",
    "    \n",
    "    # Calculate the distance of each point to the cluster center\n",
    "    distances = np.linalg.norm(cluster_points - cluster_centers[cluster_idx], axis=1)\n",
    "    \n",
    "    # Sort the points by distance (from closest to furthest)\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    used_budget = 0\n",
    "    max_uncertainty = -999\n",
    "    best_point = None\n",
    "    best_label = None\n",
    "    for idx in sorted_indices:\n",
    "        if used_budget >= budget:\n",
    "            if best_point is None:\n",
    "                best_point = cluster_points[idx].reshape(3,32,32) #Simply choose the point closest if no point can be queried.\n",
    "                best_label = selected_labels[cluster_points_indices[idx]]\n",
    "            break\n",
    "        print(f\"Point index: {cluster_points_indices[idx]}, Distance: {distances[idx]}\")\n",
    "        point = cluster_points[idx].reshape(3,32,32)\n",
    "        label = selected_labels[cluster_points_indices[idx]]\n",
    "        #Reshape the point back to input shape\n",
    "        point_tensor = torch.tensor(point).unsqueeze(0)\n",
    "        answer = prove_and_verify(point_tensor)\n",
    "        if answer > max_uncertainty:\n",
    "            max_uncertainty = answer\n",
    "            best_point = point\n",
    "            best_label = label\n",
    "        used_budget += 1\n",
    "    points_to_submit.append(best_point)    \n",
    "    labels_to_submit.append(best_label)\n",
    "assert len(points_to_submit) == K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Valuation\n",
    "\n",
    "After Bob successfully selects the points to submit, they run an MPC protocol together to evaluate the dataset. Given that Alice needs to run another pass of her model for the valuation, and the doing that with MPC is still too expensive, Bob will first send the data points to Alice (without labels) and let Alice run model inference locally. Alice will send a ZKP for Bob to verify. After that, they engage in the MPC protocol where Alice supplies the inference result, and Bob supplies the data points and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensor] decomposition error: integer -591153822 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 8338085585 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 450477056 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -1093363577 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -4626530856 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 404529974 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -78102996674 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 461253035 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 73663634318 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+-----------------+--------------+----------------+----------------+----------------+------------------+----------------+-----------------+--------------------+--------------------+------------------------+\n",
      "| mean_error      | median_error | max_error      | min_error      | mean_abs_error | median_abs_error | max_abs_error  | min_abs_error   | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+-----------------+--------------+----------------+----------------+----------------+------------------+----------------+-----------------+--------------------+--------------------+------------------------+\n",
      "| 0.0000048811735 | 0.0000776127 | 0.000102587044 | -0.00008928776 | 0.000036224126 | 0.0000776127     | 0.000102587044 | 0.0000004917383 | 0.000000001942762  | 0.000047377707     | 0.00036440432          |\n",
      "+-----------------+--------------+----------------+----------------+----------------+------------------+----------------+-----------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First the ZKP setup\n",
    "import ezkl\n",
    "import json\n",
    "\n",
    "#Clear the data firectory of previous ZKP\n",
    "import os\n",
    "import shutil\n",
    "shutil.rmtree('dataZKP', ignore_errors=True)\n",
    "os.makedirs('dataZKP', exist_ok=True)\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "model = LeNet()\n",
    "#Model export \n",
    "torch.onnx.export(model,               # model being run\n",
    "    x,                   # model input (or a tuple for multiple inputs)\n",
    "    model_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=10,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = ['input'],   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\" #Bob can see this\n",
    "py_run_args.output_visibility = \"hashed\" #This hash is given to Bob\n",
    "py_run_args.param_visibility = \"private\" \n",
    "\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "assert res\n",
    "\n",
    "indices = random.sample(range(len(trainset)), 10)\n",
    "cal_images = np.array([trainset[i][0].numpy() for i in indices])\n",
    "\n",
    "#Alice should use some real data to calibrate the model, here we use random data\n",
    "data_array = (cal_images).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res \n",
    "\n",
    "# srs path - This actually requires a trusted setup.\n",
    "res = await ezkl.get_srs(settings_path)\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Bob's data\n",
    "outputs = []\n",
    "for pts in points_to_submit:\n",
    "    data_array = pts.reshape([-1]).tolist()\n",
    "    data = dict(input_data = [data_array])\n",
    "    json.dump(data, open(data_path, 'w'))\n",
    "\n",
    "    #Alice running the model on the data points\n",
    "    model.eval()\n",
    "    inp = torch.tensor(pts).unsqueeze(0)\n",
    "    output = model(inp)\n",
    "    output = output.detach().numpy()\n",
    "    outputs.append(output)\n",
    "    #Save the output\n",
    "    data = dict(output_data = output.tolist())\n",
    "    json.dump(data, open(output_path, 'w'))\n",
    "\n",
    "    #Generate witness\n",
    "    res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert res\n",
    "\n",
    "    #Prove\n",
    "    res = ezkl.prove(witness_path, compiled_model_path, pk_path, proof_path, \"single\")\n",
    "    assert res\n",
    "\n",
    "    #Bob gets the proof then verifies it\n",
    "    res = ezkl.verify(proof_path, settings_path, vk_path)\n",
    "    assert res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Alice and Bob's private input for MPC\n",
    "Bob_input = (points_to_submit, labels_to_submit)\n",
    "Alice_input = outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
