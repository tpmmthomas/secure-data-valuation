{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malicious, multi-point scenario\n",
    "\n",
    "In this scenario, we assume Bob has multiple data points to contribute to Alice's ML model. Now Alice is trying to value the dataset as a whole, judging on the diversity, uncertainty of the datasets as well as the current model's performance on the dataset. Moreover, the parties are assumed to be malicious, which means they might deviate from the protocol to maximize their own utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup\n",
    "\n",
    "We set up Alice's model and Bob's data point as in the other examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#First, we define Alice's model M. We assume a simple CNN model.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#Don't use GPU for now\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "class LeNet(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Adaptation of LeNet that uses ReLU activations\n",
    "    \"\"\"\n",
    "\n",
    "    # network architecture:\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "model = LeNet()\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "torch.save(model.state_dict(), 'data/model.pth')\n",
    "torch.save(model, 'data/alice_model.pth')\n",
    "\n",
    "#Next, we define the data loader for CIFAR-10 dataset.\n",
    "import torchvision\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=False,transform=transform,download=True)\n",
    "\n",
    "\n",
    "# Randomly select 100 images as Bob's dataset\n",
    "indices = random.sample(range(len(trainset)), 100)\n",
    "selected_images = np.array([trainset[i][0].numpy() for i in indices])\n",
    "selected_labels = np.array([trainset[i][1]  for i in indices])\n",
    "\n",
    "# Save images and labels separately\n",
    "# torch.save(selected_images, 'data/selected_images.pth')\n",
    "# torch.save(selected_labels, 'data/selected_labels.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Clustering\n",
    "\n",
    "Before submitting points to Alice for evaluation, Bob needs to select a subset of representative data points. To do this, we recommend using K-means clustering to select a diverse set of points where K is defined by the number of data points Alice wishs to check. Bob can select a data point closest to the centroid of each cluster. It is ultimately up to Bob to decide which points to submit, even if they are not ideal so we do not need to securely compute this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers shape: (10, 3072)\n"
     ]
    }
   ],
   "source": [
    "#First, we run the Kmeans clustering algorithm locally on Bob's device\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set the number of clusters\n",
    "K = 10\n",
    "\n",
    "# Reshape the images to be a 2D array (each image is flattened)\n",
    "flattened_images = selected_images.reshape(selected_images.shape[0], -1)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(flattened_images)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "print(\"Cluster centers shape:\", cluster_centers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further make an enhancement to pure K-means selection by trying to select the most uncertain points in each cluster. As determining the uncertainty requires model inference, we define a computing budget B which is the number of points Bob and Alice can afford to evaluate. \n",
    "\n",
    "In the malicious case however, computing model inference via a secure multi-party computation protocol is not very feasible, as such computation is extremely expensive. Therefore, we will allow Alice to see the data point (without labels) and compute the model inference herself. A ZKP will be required from Alice to prove the correctness of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0057], grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Set up\n",
    "\n",
    "#First, a slightly modified version of the model \n",
    "#that returns the difference between the top 2 probs of the output.\n",
    "class LeNetZKP(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Adaptation of LeNet that uses ReLU activations\n",
    "    \"\"\"\n",
    "\n",
    "    # network architecture:\n",
    "    def __init__(self):\n",
    "        super(LeNetZKP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        top2_values, _ = torch.topk(x, 2)\n",
    "        diff = top2_values[:, 0] - top2_values[:, 1]\n",
    "        return -diff\n",
    "\n",
    "modelZK = LeNetZKP()\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "y = modelZK(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directory if not exists\n",
    "os.makedirs('dataZKP', exist_ok=True)\n",
    "#Specifying some path parameters\n",
    "model_path = os.path.join('dataZKP','network.onnx')\n",
    "compiled_model_path = os.path.join('dataZKP','network.compiled')\n",
    "pk_path = os.path.join('dataZKP','test.pk')\n",
    "vk_path = os.path.join('dataZKP','test.vk')\n",
    "settings_path = os.path.join('dataZKP','settings.json')\n",
    "\n",
    "witness_path = os.path.join('dataZKP','witness.json')\n",
    "data_path = os.path.join('dataZKP','input.json')\n",
    "output_path = os.path.join('dataZKP','output.json')\n",
    "label_path = os.path.join('dataZKP','label.json')\n",
    "proof_path = os.path.join('dataZKP','test.pf')\n",
    "cal_path = os.path.join('dataZKP',\"calibration.json\")\n",
    "\n",
    "#Model export \n",
    "torch.onnx.export(modelZK,               # model being run\n",
    "    x,                   # model input (or a tuple for multiple inputs)\n",
    "    model_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=10,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = ['input'],   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensor] decomposition error: integer 1521069695 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 6150941173 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 848370728 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 31762220593 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -30519212463 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 674806204 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer -135647197356 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 839386224 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "[tensor] decomposition error: integer 43963763256 is too large to be represented by base 16384 and n 2\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+---------------+---------------+---------------+-----------------+----------------+------------------+---------------+-----------------+--------------------+--------------------+------------------------+\n",
      "| mean_error    | median_error  | max_error     | min_error       | mean_abs_error | median_abs_error | max_abs_error | min_abs_error   | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+---------------+---------------+---------------+-----------------+----------------+------------------+---------------+-----------------+--------------------+--------------------+------------------------+\n",
      "| 0.00002494529 | 0.00006719679 | 0.00006719679 | -0.000053949654 | 0.00003880039  | 0.00006719679    | 0.00006719679 | 0.0000072941184 | 0.0000000018800066 | -0.0026351141      | 0.004176683            |\n",
      "+---------------+---------------+---------------+-----------------+----------------+------------------+---------------+-----------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Settigns, calibration\n",
    "import ezkl\n",
    "import json \n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\" #Bob can see this\n",
    "py_run_args.output_visibility = \"public\" #This is also public as Bob needs to know the uncertainty\n",
    "py_run_args.param_visibility = \"private\" \n",
    "\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "assert res\n",
    "\n",
    "indices = random.sample(range(len(trainset)), 10)\n",
    "cal_images = np.array([trainset[i][0].numpy() for i in indices])\n",
    "\n",
    "#Alice should use some real data to calibrate the model, here we use random data\n",
    "data_array = (cal_images).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res \n",
    "\n",
    "# srs path - This actually requires a trusted setup.\n",
    "res = await ezkl.get_srs(settings_path)\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the ZKP prove and verify process into one function for convenience\n",
    "import time\n",
    "\n",
    "def prove_and_verify(prover_input: torch.Tensor):\n",
    "    print(prover_input) # I do not know why, but this line avoided errors in verifying the proof\n",
    "    # Serialize the prover input into a file\n",
    "    data_array = prover_input.detach().numpy().reshape([-1]).tolist()\n",
    "    data = dict(input_data = [data_array])\n",
    "    json.dump(data, open(data_path, 'w'))\n",
    "    \n",
    "    # This simulates Alice running the model inference\n",
    "    modelZK.eval()\n",
    "    output = modelZK(prover_input)\n",
    "    print(output)\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    #Generate witness\n",
    "    res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert res\n",
    "    print(\"Done witness\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # Prove\n",
    "    res = ezkl.prove(witness_path, compiled_model_path, pk_path, proof_path, \"single\")\n",
    "    assert res\n",
    "    print(\"Done proving\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # Verify\n",
    "    res = ezkl.verify(proof_path, settings_path, vk_path)\n",
    "    assert res\n",
    "    print(\"Done verifying\")\n",
    "    return output.detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point index: 25, Distance: 12.21451473236084\n",
      "Point index: 29, Distance: 12.892363548278809\n",
      "Point index: 80, Distance: 19.555753707885742\n",
      "Point index: 61, Distance: 19.875537872314453\n",
      "Point index: 33, Distance: 12.747353553771973\n",
      "Point index: 75, Distance: 16.550493240356445\n",
      "Point index: 96, Distance: 12.784943580627441\n",
      "Point index: 19, Distance: 17.528596878051758\n",
      "Point index: 92, Distance: 12.973246574401855\n",
      "Point index: 6, Distance: 13.660115242004395\n",
      "Point index: 98, Distance: 8.920341088014538e-07\n",
      "Point index: 88, Distance: 10.95488166809082\n",
      "Point index: 35, Distance: 12.03993034362793\n",
      "Point index: 66, Distance: 9.289745435125951e-07\n",
      "Point index: 44, Distance: 16.228557586669922\n",
      "Point index: 59, Distance: 19.96954917907715\n",
      "Point index: 60, Distance: 1.090918658519513e-06\n"
     ]
    }
   ],
   "source": [
    "TOTAL_BUDGET = 20 #This means maximum of 3 queries per cluster\n",
    "budget = TOTAL_BUDGET // K\n",
    "# Loop through each cluster\n",
    "points_to_submit = []\n",
    "labels_to_submit = []\n",
    "for cluster_idx in range(K):\n",
    "    # Get the indices of points in the current cluster\n",
    "    cluster_points_indices = np.where(cluster_labels == cluster_idx)[0]\n",
    "    \n",
    "    # Get the points in the current cluster\n",
    "    cluster_points = flattened_images[cluster_points_indices]\n",
    "    \n",
    "    # Calculate the distance of each point to the cluster center\n",
    "    distances = np.linalg.norm(cluster_points - cluster_centers[cluster_idx], axis=1)\n",
    "    \n",
    "    # Sort the points by distance (from closest to furthest)\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    used_budget = 0\n",
    "    max_uncertainty = -999\n",
    "    best_point = None\n",
    "    best_label = None\n",
    "    for idx in sorted_indices:\n",
    "        if used_budget >= budget:\n",
    "            if best_point is None:\n",
    "                best_point = cluster_points[idx].reshape(3,32,32) #Simply choose the point closest if no point can be queried.\n",
    "                best_label = selected_labels[cluster_points_indices[idx]]\n",
    "            break\n",
    "        print(f\"Point index: {cluster_points_indices[idx]}, Distance: {distances[idx]}\")\n",
    "        point = cluster_points[idx].reshape(3,32,32)\n",
    "        label = selected_labels[cluster_points_indices[idx]]\n",
    "        #Reshape the point back to input shape\n",
    "        point_tensor = torch.tensor(point).unsqueeze(0)\n",
    "        answer = 1#prove_and_verify(point_tensor)\n",
    "        if answer > max_uncertainty:\n",
    "            max_uncertainty = answer\n",
    "            best_point = point\n",
    "            best_label = label\n",
    "        used_budget += 1\n",
    "    points_to_submit.append(best_point)    \n",
    "    labels_to_submit.append(best_label)\n",
    "assert len(points_to_submit) == K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Valuation\n",
    "\n",
    "After Bob successfully selects the points to submit, they run an MPC protocol together to evaluate the dataset. Given that Alice needs to run another pass of her model for the valuation, and the doing that with MPC is still too expensive, Bob will first send the data points to Alice (without labels) and let Alice run model inference locally. Alice will send a ZKP for Bob to verify. After that, they engage in the MPC protocol where Alice supplies the inference result, and Bob supplies the data points and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First the ZKP setup\n",
    "import ezkl\n",
    "import json\n",
    "\n",
    "#Clear the data firectory of previous ZKP\n",
    "import os\n",
    "import shutil\n",
    "shutil.rmtree('dataZKP', ignore_errors=True)\n",
    "os.makedirs('dataZKP', exist_ok=True)\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "model = LeNet()\n",
    "#Model export \n",
    "torch.onnx.export(model,               # model being run\n",
    "    x,                   # model input (or a tuple for multiple inputs)\n",
    "    model_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=10,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = ['input'],   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\" #Bob can see this\n",
    "py_run_args.output_visibility = \"hashed\" #This hash is given to Bob\n",
    "py_run_args.param_visibility = \"private\" \n",
    "\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "assert res\n",
    "\n",
    "indices = random.sample(range(len(trainset)), 10)\n",
    "cal_images = np.array([trainset[i][0].numpy() for i in indices])\n",
    "\n",
    "#Alice should use some real data to calibrate the model, here we use random data\n",
    "data_array = (cal_images).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "# await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res \n",
    "\n",
    "# srs path - This actually requires a trusted setup.\n",
    "res = await ezkl.get_srs(settings_path)\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (double) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     11\u001b[0m inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(pts)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     14\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36mLeNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv2/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv2/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv2/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv2/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "#Prepare Bob's data\n",
    "points_to_submit = list(np.ones((10,3,32,32)) * 0.5)\n",
    "outputs = []\n",
    "# for pts in points_to_submit:\n",
    "data_array = points_to_submit.reshape([-1]).tolist()\n",
    "data = dict(input_data = [data_array])\n",
    "json.dump(data, open(data_path, 'w'))\n",
    "\n",
    "#Alice running the model on the data points\n",
    "model.eval()\n",
    "inp = torch.tensor(points_to_submit).unsqueeze(0)\n",
    "output = model(inp)\n",
    "output = output.detach().numpy()\n",
    "outputs.append(output)\n",
    "#Save the output\n",
    "data = dict(output_data = output.tolist())\n",
    "json.dump(data, open(output_path, 'w'))\n",
    "\n",
    "#Generate witness\n",
    "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "assert res\n",
    "time.sleep(0.1)\n",
    "#Prove\n",
    "res = ezkl.prove(witness_path, compiled_model_path, pk_path, proof_path, \"single\")\n",
    "assert res\n",
    "time.sleep(0.1)\n",
    "#Bob gets the proof then verifies it\n",
    "res = ezkl.verify(proof_path, settings_path, vk_path)\n",
    "assert res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30720\n",
      "(10, 10)\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Prepare Alice and Bob's private input for MPC\n",
    "Bob_input = (points_to_submit, labels_to_submit)\n",
    "Alice_input = outputs\n",
    "if not os.path.exists('../../MP-SPDZ/Player-Data'):\n",
    "    os.makedirs('../../MP-SPDZ/Player-Data')\n",
    "p0_path = os.path.join('../../MP-SPDZ/Player-Data','Input-P0-0')\n",
    "p1_path = os.path.join('../../MP-SPDZ/Player-Data','Input-P1-0')\n",
    "\n",
    "#Turn points to submit into a 1D list\n",
    "points_1d = np.array(points_to_submit).reshape(-1).tolist()\n",
    "print(len(points_1d))\n",
    "#Convert labels into one-hot encoding\n",
    "one_hot_labels = np.eye(10)[labels_to_submit]\n",
    "print(one_hot_labels.shape)\n",
    "one_hot_labels = one_hot_labels.reshape(-1).tolist()\n",
    "print(len(one_hot_labels))\n",
    "with open(p0_path, 'w') as f:\n",
    "    f.write(' '.join(map(lambda x : f\"{x:.6f}\", points_1d)))\n",
    "    f.write(' ')\n",
    "    f.write(' '.join(map(lambda x : f\"{x:.6f}\", one_hot_labels)))\n",
    "    f.write('\\n')\n",
    "#Alice's input\n",
    "outputs = np.array(outputs).reshape(-1).tolist()\n",
    "print(len(outputs))\n",
    "with open(p1_path, 'w') as f:\n",
    "    f.write(' '.join(map(lambda x : f\"{x:.6f}\", outputs)))\n",
    "    f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bit length for compilation: 64\n",
      "Default security parameter for compilation: 40\n",
      "Compiling file Programs/Source/multi_point_val.mpc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Order of memory instructions not preserved, errors possible\n",
      "WARNING: Probabilistic truncation leaks some information, see https://eprint.iacr.org/2024/1127 for discussion. Use 'sfix.round_nearest = True' to deactivate this for fixed-point operations.\n",
      "Writing to Programs/Bytecode/multi_point_val-FPDiv(4)_31_16-1.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-TruncPr(20)_47_16-3.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-FPDiv(2)_31_16-5.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-TruncPr(9)_47_16-6.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-TruncPr(3)_47_16-7.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-sqrt(17)_31_16-8.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-sqrt(12)_31_16-10.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-FPDiv(1)_31_16-11.bc\n",
      "Compiled 100000 lines at Fri Jan 31 02:44:49 2025\n",
      "Writing to Programs/Bytecode/multi_point_val-log2_fx(100)_31_16-12.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-TruncPr(100)_47_16-14.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-FPDiv(100)_31_16-15.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-TruncPr(50)_47_16-16.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-log2_fx(10)_31_16-17.bc\n",
      "Writing to Programs/Bytecode/multi_point_val-FPDiv(10)_31_16-18.bc\n",
      "Writing to Programs/Schedules/multi_point_val.sch\n",
      "Writing to Programs/Bytecode/multi_point_val-0.bc\n",
      "Hash: d9a25ee0448f5d441f8896e50a5b0753bb62bc37976337576d0e5113d28e020f\n",
      "Program requires at most:\n",
      "       30820 integer inputs from player 0\n",
      "     3470204 integer triples\n",
      "    18356704 integer bits\n",
      "      200808 integer opens\n",
      "         100 integer inputs from player 1\n",
      "       93609 virtual machine rounds\n"
     ]
    }
   ],
   "source": [
    "#The code for valuation is prepared in ../../MP-SPDZ/Programs/Source/multi_point_val.mpc\n",
    "# Here we compile the MPC code \n",
    "! cd ../../MP-SPDZ && ./compile.py multi_point_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/thomas/secure-data-valuation/MP-SPDZ/Scripts/../mascot-party.x 0 multi_point_val -pn 16513 -h localhost -N 2\n",
      "Running /home/thomas/secure-data-valuation/MP-SPDZ/Scripts/../mascot-party.x 1 multi_point_val -pn 16513 -h localhost -N 2\n",
      "Using statistical security parameter 40\n",
      "^C\n",
      "=== Party 1\n",
      "Using statistical security parameter 40\n",
      "Time taken for squared loss computation: 471.6497230529785\n"
     ]
    }
   ],
   "source": [
    "#MPC for squared loss\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "! cd ../../MP-SPDZ/ && Scripts/mascot.sh multi_point_val\n",
    "end = time.time()\n",
    "print(f\"Time taken for squared loss computation: {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using statistical security parameter 40\n",
    "Diversity score: 0.446701\n",
    "Uncertainty score: 2.30075\n",
    "Loss score: 2.30194\n",
    "Final Valuation: 1.74501\n",
    "The following benchmarks are including preprocessing (offline phase).\n",
    "Time = 1709.5 seconds \n",
    "Data sent = 46213.5 MB in ~606767 rounds (party 0 only; use '-v' for more details)\n",
    "Global data sent = 92422.2 MB (all parties)\n",
    "This program might benefit from some protocol options.\n",
    "Consider adding the following at the beginning of your code:\n",
    "        program.use_edabit(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
