{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# kzg-ezkl\n",
                "\n",
                "Here's an example leveraging EZKL whereby the inputs to the model, and the model params themselves, are committed to using kzg-commitments inside a circuit.\n",
                "\n",
                "In this setup:\n",
                "- the commitments are publicly known to the prover and verifier\n",
                "\n",
                "\n",
                "We leave the outputs of the model as public as well (known to the  verifier and prover). \n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First we import the necessary dependencies and set up logging to be as informative as possible. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if notebook is in colab\n",
                "try:\n",
                "    # install ezkl\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
                "\n",
                "# rely on local installation of ezkl if the notebook is not in colab\n",
                "except:\n",
                "    pass\n",
                "\n",
                "from torch import nn\n",
                "import ezkl\n",
                "import os\n",
                "import json\n",
                "import logging\n",
                "\n",
                "# uncomment for more descriptive logging \n",
                "FORMAT = '%(levelname)s %(name)s %(asctime)-15s %(filename)s:%(lineno)d %(message)s'\n",
                "logging.basicConfig(format=FORMAT)\n",
                "logging.getLogger().setLevel(logging.INFO)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we define our model. It is a humble model with but a conv layer and a $ReLU$ non-linearity, but it is a model nonetheless"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "# Defines the model\n",
                "# we got convs, we got relu, \n",
                "# What else could one want ????\n",
                "\n",
                "class MyModel(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(MyModel, self).__init__()\n",
                "\n",
                "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=4)\n",
                "        self.relu = nn.ReLU()\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        x = self.relu(x)\n",
                "\n",
                "        return x\n",
                "\n",
                "\n",
                "circuit = MyModel()\n",
                "\n",
                "# this is where you'd train your model\n",
                "\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We omit training for purposes of this demonstration. We've marked where training would happen in the cell above. \n",
                "Now we export the model to onnx and create a corresponding (randomly generated) input file.\n",
                "\n",
                "You can replace the random `x` with real data if you so wish. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = torch.rand(1,*[3, 8, 8], requires_grad=True)\n",
                "\n",
                "# Flips the neural net into inference mode\n",
                "circuit.eval()\n",
                "\n",
                "    # Export the model\n",
                "torch.onnx.export(circuit,               # model being run\n",
                "                      x,                   # model input (or a tuple for multiple inputs)\n",
                "                      \"network.onnx\",            # where to save the model (can be a file or file-like object)\n",
                "                      export_params=True,        # store the trained parameter weights inside the model file\n",
                "                      opset_version=10,          # the ONNX version to export the model to\n",
                "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                      input_names = ['input'],   # the model's input names\n",
                "                      output_names = ['output'], # the model's output names\n",
                "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
                "                                    'output' : {0 : 'batch_size'}})\n",
                "\n",
                "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
                "\n",
                "data = dict(input_data = [data_array])\n",
                "\n",
                "    # Serialize data into file:\n",
                "json.dump( data, open(\"input.json\", 'w' ))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is where the magic happens. We define our `PyRunArgs` objects which contains the visibility parameters for out model. \n",
                "- `input_visibility` defines the visibility of the model inputs\n",
                "- `param_visibility` defines the visibility of the model weights and constants and parameters \n",
                "- `output_visibility` defines the visibility of the model outputs\n",
                "\n",
                "There are currently 6 visibility settings:\n",
                "- `public`: known to both the verifier and prover (a subtle nuance is that this may not be the case for model parameters but until we have more rigorous theoretical results we don't want to make strong claims as to this). \n",
                "- `private`: known only to the prover\n",
                "- `fixed`: known to the prover and verifier (as a commit), but not modifiable by the prover.\n",
                "- `hashed`: the hash pre-image is known to the prover, the prover and verifier know the hash. The prover proves that the they know the pre-image to the hash. \n",
                "- `encrypted`: the non-encrypted element and the secret key used for decryption are known to the prover. The prover and the verifier know the encrypted element, the public key used to encrypt, and the hash of the decryption hey. The prover proves that they know the pre-image of the hashed decryption key and that this key can in fact decrypt the encrypted message.\n",
                "- `polycommit`: unblinded advice column which generates a kzg commitment. This doesn't appear in the instances of the circuit and must instead be modified directly within the proof bytes.  \n",
                "\n",
                "Here we create the following setup:\n",
                "- `input_visibility`: \"polycommit\"\n",
                "- `param_visibility`: \"polycommit\"\n",
                "- `output_visibility`: public\n",
                "\n",
                "We encourage you to play around with other setups :) \n",
                "\n",
                "Shoutouts: \n",
                "\n",
                "- [summa-solvency](https://github.com/summa-dev/summa-solvency) for their help with the poseidon hashing chip. \n",
                "- [timeofey](https://github.com/timoftime) for providing inspiration in our development of the el-gamal encryption circuit in Halo2. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ezkl\n",
                "\n",
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "\n",
                "data_path = os.path.join('input.json')\n",
                "\n",
                "run_args = ezkl.PyRunArgs()\n",
                "run_args.input_visibility = \"polycommit\"\n",
                "run_args.param_visibility = \"polycommit\"\n",
                "run_args.output_visibility = \"public\"\n",
                "run_args.variables = [(\"batch_size\", 1)]\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we generate a settings file. This file basically instantiates a bunch of parameters that determine their circuit shape, size etc... Because of the way we represent nonlinearities in the circuit (using Halo2's [lookup tables](https://zcash.github.io/halo2/design/proving-system/lookup.html)), it is often best to _calibrate_ this settings file as some data can fall out of range of these lookups.\n",
                "\n",
                "You can pass a dataset for calibration that will be representative of real inputs you might find if and when you deploy the prover. Here we create a dummy calibration dataset for demonstration purposes. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.execute 2025-01-18 06:39:33,950 execute.rs:994 num calibration batches: 11\n",
                        "INFO tract_linalg.x86_64_fma 2025-01-18 06:39:33,953 x86_64_fma.rs:24 qmmm_i32: x86_64/avx2 activated\n",
                        "INFO tract_linalg.x86_64_fma 2025-01-18 06:39:33,955 x86_64_fma.rs:116 found f16c, added fake-f16 and q40-able kernels\n",
                        "INFO tract_linalg.x86_64_fma 2025-01-18 06:39:33,956 x86_64_fma.rs:119 mmm_f32, mmv_f32, sigmoid_f32, tanh_f32: x86_64/fma activated\n",
                        "WARNING ezkl.execute 2025-01-18 06:39:36,773 execute.rs:1295 \n",
                        "\n",
                        " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
                        "\n",
                        "+---------------+---------------+---------------+---------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
                        "| mean_error    | median_error  | max_error     | min_error     | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
                        "+---------------+---------------+---------------+---------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
                        "| 0.00014199283 | 0.00009049103 | 0.00020942092 | 0.00008922815 | 0.00014199283  | 0.00009049103    | 0.00020942092 | 0.00008922815 | 0.000000022093367  | 0.00077448896      | 0.00077448896          |\n",
                        "+---------------+---------------+---------------+---------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# generate a bunch of dummy calibration data\n",
                "cal_data = {\n",
                "    \"input_data\": [torch.cat((x, torch.rand(10, *[3, 8, 8]))).flatten().tolist()],\n",
                "}\n",
                "\n",
                "cal_path = os.path.join('val_data.json')\n",
                "# save as json file\n",
                "with open(cal_path, \"w\") as f:\n",
                "    json.dump(cal_data, f)\n",
                "\n",
                "res = await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As we use Halo2 with KZG-commitments we need an SRS string from (preferably) a multi-party trusted setup ceremony. For an overview of the procedures for such a ceremony check out [this page](https://blog.ethereum.org/2023/01/16/announcing-kzg-ceremony). The `get_srs` command retrieves a correctly sized SRS given the calibrated settings file from [here](https://github.com/han0110/halo2-kzg-srs). \n",
                "\n",
                "These SRS were generated with [this](https://github.com/privacy-scaling-explorations/perpetualpowersoftau) ceremony. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.execute 2025-01-18 06:39:43,426 execute.rs:697 SRS already exists at that path\n",
                        "INFO ezkl.execute 2025-01-18 06:39:43,441 execute.rs:596 read 4194564 bytes from file (vector of len = 4194564)\n",
                        "INFO ezkl.execute 2025-01-18 06:39:43,453 execute.rs:603 file hash: 90807800a1c3b248a452e1732c45ee5099f38b737356f5542c0584ec9c3ebb45\n"
                    ]
                }
            ],
            "source": [
                "res = await ezkl.get_srs( settings_path)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we setup verifying and proving keys for the circuit. As the name suggests the proving key is needed for ... proving and the verifying key is needed for ... verifying. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.graph.model 2025-01-18 06:39:49,276 model.rs:1074 model layout...\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:39:49,288 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_-1_1\"\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:39:49,291 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_0_16383\"\n",
                        "INFO ezkl.pfsys 2025-01-18 06:39:50,368 mod.rs:542 VK took 1.267\n",
                        "INFO ezkl.graph.model 2025-01-18 06:39:50,401 model.rs:1074 model layout...\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:39:50,403 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_-1_1\"\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:39:50,405 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_0_16383\"\n",
                        "INFO ezkl.pfsys 2025-01-18 06:39:51,462 mod.rs:548 PK took 1.88\n",
                        "INFO ezkl.pfsys 2025-01-18 06:39:51,465 mod.rs:867 done saving verification key ✅\n",
                        "INFO ezkl.pfsys 2025-01-18 06:39:52,736 mod.rs:850 done saving proving key ✅\n"
                    ]
                }
            ],
            "source": [
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        \n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now need to generate the (partial) circuit witness. These are the model outputs (and any hashes) that are generated when feeding the previously generated `input.json` through the circuit / model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.pfsys 2025-01-18 06:40:17,095 mod.rs:810 loaded verification key ✅\n"
                    ]
                }
            ],
            "source": [
                "!export RUST_BACKTRACE=1\n",
                "\n",
                "witness_path = \"witness.json\"\n",
                "\n",
                "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path, vk_path)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As a sanity check you can \"mock prove\" (i.e check that all the constraints of the circuit match without generate a full proof). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.execute 2025-01-18 06:40:18,648 execute.rs:1346 Mock proof\n",
                        "INFO ezkl.graph.model 2025-01-18 06:40:18,700 model.rs:1074 model layout...\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:40:18,703 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_-1_1\"\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:40:18,704 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_0_16383\"\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "res = ezkl.mock(witness_path, compiled_model_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we generate a full proof. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.pfsys 2025-01-18 06:40:25,892 mod.rs:833 loaded proving key ✅\n",
                        "INFO ezkl.pfsys 2025-01-18 06:40:25,909 mod.rs:604 proof started...\n",
                        "INFO ezkl.graph.model 2025-01-18 06:40:25,996 model.rs:1074 model layout...\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:40:25,999 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_-1_1\"\n",
                        "INFO ezkl.circuit.table 2025-01-18 06:40:26,000 table.rs:433 Loading range check table from cache: \"/home/thomas/.ezkl/cache/rangecheck_0_16383\"\n",
                        "INFO ezkl.pfsys 2025-01-18 06:40:28,009 mod.rs:643 proof took 2.83\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'instances': [['2a58140100000000000000000000000000000000000000000000000000000000']], 'proof': '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', 'transcript_type': 'EVM'}\n"
                    ]
                }
            ],
            "source": [
                "# GENERATE A PROOF\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        \n",
                "        \"single\",\n",
                "    )\n",
                "\n",
                "print(res)\n",
                "assert os.path.isfile(proof_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we need to swap out the public commitments inside the corresponding proof bytes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.swap_proof_commitments(proof_path, witness_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And verify it as a sanity check. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO ezkl.pfsys 2025-01-18 06:41:30,820 mod.rs:810 loaded verification key ✅\n",
                        "INFO ezkl.execute 2025-01-18 06:41:30,842 execute.rs:2415 verify took 0.14\n",
                        "INFO ezkl.execute 2025-01-18 06:41:30,844 execute.rs:2420 verified: true\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "verified\n"
                    ]
                }
            ],
            "source": [
                "# VERIFY IT\n",
                "\n",
                "res \n",
                "\n",
                "\n",
                "res = ezkl.verify(\n",
                "        proof_path,\n",
                "        settings_path,\n",
                "        vk_path,\n",
                "        \n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "print(\"verified\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now create an EVM / `.sol` verifier that can be deployed on chain to verify submitted proofs using a view function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "abi_path = 'test.abi'\n",
                "sol_code_path = 'test.sol'\n",
                "\n",
                "res = await ezkl.create_evm_verifier(\n",
                "        vk_path,\n",
                "        \n",
                "        settings_path,\n",
                "        sol_code_path,\n",
                "        abi_path,\n",
                "    )\n",
                "assert res == True\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verify on the evm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make sure anvil is running locally first\n",
                "# run with $ anvil -p 3030\n",
                "# we use the default anvil node here\n",
                "import json\n",
                "\n",
                "address_path = os.path.join(\"address.json\")\n",
                "\n",
                "res = await ezkl.deploy_evm(\n",
                "    address_path,\n",
                "    sol_code_path,\n",
                "    'http://127.0.0.1:3030'\n",
                ")\n",
                "\n",
                "assert res == True\n",
                "\n",
                "with open(address_path, 'r') as file:\n",
                "    addr = file.read().rstrip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make sure anvil is running locally\n",
                "# $ anvil -p 3030\n",
                "\n",
                "res = await ezkl.verify_evm(\n",
                "    addr,\n",
                "    proof_path,\n",
                "    \"http://127.0.0.1:3030\"\n",
                ")\n",
                "assert res == True"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "sdv2",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
